geom_hline(yintercept = 0, color = "red") +
ggtitle("VAR with 30 PCs: Residual Plot") +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(paste0(base_filename, "_residuals.pdf"), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle("VAR with 30 PCs: Actual vs Predicted") +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(paste0(base_filename, "_scatter.pdf"), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
plots_folder_all <- "var_all_variables_results"
if (!dir.exists(plots_folder_all)) {
dir.create(plots_folder_all)
}
# Ensure alignment of lagged variables
rows_to_keep <- min(nrow(X_train_matrix), length(Y_train_vec))
Y_train_aligned <- Y_train_vec[1:rows_to_keep]
X_train_aligned <- X_train_matrix[1:rows_to_keep, ]
n_test <- length(Y_test_vec)
predictions <- numeric(n_test)
for (i in 1:n_test) {
# Standardize the current training data
mean_Y_train <- mean(Y_train_aligned)
sd_Y_train <- sd(Y_train_aligned)
Y_train_standardized <- (Y_train_aligned - mean_Y_train) / sd_Y_train
mean_X_train <- colMeans(X_train_aligned)
sd_X_train <- apply(X_train_aligned, 2, sd)
X_train_standardized <- scale(X_train_aligned, center = mean_X_train, scale = sd_X_train)
train_data_standardized <- data.frame(Y = Y_train_standardized, X_train_standardized)
# Fit the VAR model without additional lagging
var_model <- VAR(train_data_standardized, p = 1)
# Forecast the next step
current_test_X <- matrix(X_test_matrix[i, ], nrow = 1)
current_test_X <- scale(current_test_X, center = mean_X_train, scale = sd_X_train)
var_forecast <- predict(var_model, n.ahead = 1)
prediction_standardized <- var_forecast$fcst$Y[1, "fcst"]
# De-standardize the prediction
prediction <- prediction_standardized * sd_Y_train + mean_Y_train
predictions[i] <- prediction
# Update training data
actual_value <- Y_test_vec[i]
Y_train_aligned <- c(Y_train_aligned, actual_value)
X_train_aligned <- rbind(X_train_aligned, X_test_matrix[i, ])
}
# Metrics
actual_values <- Y_test_vec[1:n_test]
test_errors <- actual_values - predictions
test_mae <- mean(abs(test_errors))
test_mse <- mean(test_errors^2)
test_rmse <- sqrt(test_mse)
# Print metrics
cat("Test Mean Absolute Error (MAE):", test_mae, "\n")
cat("Test Mean Squared Error (MSE):", test_mse, "\n")
cat("Test Root Mean Squared Error (RMSE):", test_rmse, "\n")
# Prepare data frame for plotting
df_test <- data.frame(Date = Y_test_with_date$date, Actual = actual_values, Predicted = predictions)
# Save plots in the specified folder
base_filename <- file.path(plots_folder_all, "var_all")
# Time series plot
time_series_plot <- ggplot(df_test, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = Predicted, color = "Predicted")) +
labs(title = "VAR with All Predictors: Actual vs Predicted",
x = "Date", y = "CPIULFSL", color = "Legend") +
theme_minimal() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))
ggsave(paste0(base_filename, "_timeseries.pdf"), plot = time_series_plot, width = 10, height = 8, dpi = 300, units = "in")
# Residual plot
residual_plot <- ggplot(df_test, aes(x = Actual, y = Actual - Predicted)) +
geom_point() +
geom_hline(yintercept = 0, color = "red") +
ggtitle("VAR with All Predictors: Residual Plot") +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(paste0(base_filename, "_residuals.pdf"), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle("VAR with All Predictors: Actual vs Predicted") +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(paste0(base_filename, "_scatter.pdf"), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
# Load required libraries
suppressWarnings(suppressMessages({
library(stats)
library(vars)
library(ggplot2)
}))
perform_var_with_pca <- function(pc_values, output_folder) {
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Initialize variables for recursive rolling predictions
Y_train_vec <- as.numeric(Y_train)
X_train_matrix <- as.matrix(X_train)
Y_test_vec <- as.numeric(Y_test)
X_test_matrix <- as.matrix(X_test)
# Apply PCA to the training data
train_pca <- prcomp(X_train_matrix, center = TRUE, scale. = TRUE)
test_pca <- predict(train_pca, newdata = X_test_matrix)  # Transform test data
# Data frame to store results
results <- data.frame(PCs = pc_values, MSE = NA, MAE = NA, RMSE = NA)
for (pc in pc_values) {
cat("Testing VAR with", pc, "PCs\n")
train_pca_matrix <- train_pca$x[, 1:pc]  # Select specified number of PCs
test_pca_matrix <- test_pca[, 1:pc]
n_test <- length(Y_test_vec)
predictions <- numeric(n_test)
for (i in 1:n_test) {
# Standardize the current training data
mean_Y_train <- mean(Y_train_vec)
sd_Y_train <- sd(Y_train_vec)
Y_train_standardized <- (Y_train_vec - mean_Y_train) / sd_Y_train
mean_train_pca <- colMeans(train_pca_matrix)
sd_train_pca <- apply(train_pca_matrix, 2, sd)
train_pca_standardized <- scale(train_pca_matrix, center = mean_train_pca, scale = sd_train_pca)
train_data_standardized <- data.frame(Y = Y_train_standardized, train_pca_standardized)
# Fit the VAR model without additional lagging
var_model <- VAR(train_data_standardized, p = 1)
# Forecast the next step
current_test_pca <- matrix(test_pca_matrix[i, ], nrow = 1)
test_pca_standardized <- scale(current_test_pca, center = mean_train_pca, scale = sd_train_pca)
var_forecast <- predict(var_model, n.ahead = 1)
prediction_standardized <- var_forecast$fcst$Y[1, "fcst"]
# De-standardize the prediction
prediction <- prediction_standardized * sd_Y_train + mean_Y_train
predictions[i] <- prediction
# Update training data
actual_value <- Y_test_vec[i]
Y_train_vec <- c(Y_train_vec, actual_value)
train_pca_matrix <- rbind(train_pca_matrix, test_pca_matrix[i, ])
}
# Metrics
actual_values <- Y_test_vec[1:n_test]
test_errors <- actual_values - predictions
test_mae <- mean(abs(test_errors))
test_mse <- mean(test_errors^2)
test_rmse <- sqrt(test_mse)
# Store metrics
results[results$PCs == pc, ] <- c(pc, test_mse, test_mae, test_rmse)
# Print metrics
cat("PCs:", pc, "MAE:", test_mae, "MSE:", test_mse, "RMSE:", test_rmse, "\n")
# Save plots in the specified folder
base_filename <- file.path(output_folder, paste0("var_", pc, "_pcs"))
# Prepare data frame for plotting
df_test <- data.frame(Date = Y_test_with_date$date, Actual = actual_values, Predicted = predictions)
# Time series plot
time_series_plot <- ggplot(df_test, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = Predicted, color = "Predicted")) +
labs(title = paste("VAR with", pc, "PCs: Actual vs Predicted"),
x = "Date", y = "CPIULFSL", color = "Legend") +
theme_minimal() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))
ggsave(paste0(base_filename, "_timeseries.pdf"), plot = time_series_plot, width = 10, height = 8, dpi = 300, units = "in")
# Residual plot
residual_plot <- ggplot(df_test, aes(x = Actual, y = Actual - Predicted)) +
geom_point() +
geom_hline(yintercept = 0, color = "red") +
ggtitle(paste("VAR Residual Plot (PCs =", pc, ")")) +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(paste0(base_filename, "_residuals.pdf"), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle(paste("VAR: Actual vs Predicted (PCs =", pc, ")")) +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(paste0(base_filename, "_scatter.pdf"), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
}
return(results)
}
# Define the number of PCs to test
pc_values <- c(5, 10, 15, 20, 25, 30, 35, 40)
output_folder <- "var_pca_results"
results <- perform_var_with_pca(pc_values, output_folder)
suppressWarnings(suppressMessages({
library(stats)
library(vars)
library(ggplot2)
}))
perform_var_with_pca <- function(pc_values, output_folder) {
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Initialize variables for recursive rolling predictions
Y_train_vec <- as.numeric(Y_train)
X_train_matrix <- as.matrix(X_train)
Y_test_vec <- as.numeric(Y_test)
X_test_matrix <- as.matrix(X_test)
# Perform PCA once on the training data
train_pca <- prcomp(X_train_matrix, center = TRUE, scale. = TRUE)
test_pca <- predict(train_pca, newdata = X_test_matrix)  # Transform test data
# Data frame to store results
results <- data.frame(PCs = pc_values, MAE = NA, MSE = NA, RMSE = NA)
for (pc in pc_values) {
cat("Testing VAR with", pc, "PCs\n")
# Select the required number of PCs
train_pca_matrix <- train_pca$x[, 1:pc]
test_pca_matrix <- test_pca[, 1:pc]
n_test <- length(Y_test_vec)
predictions <- numeric(n_test)
for (i in 1:n_test) {
# Standardize the current training data
mean_Y_train <- mean(Y_train_vec)
sd_Y_train <- sd(Y_train_vec)
Y_train_standardized <- (Y_train_vec - mean_Y_train) / sd_Y_train
mean_train_pca <- colMeans(train_pca_matrix)
sd_train_pca <- apply(train_pca_matrix, 2, sd)
train_pca_standardized <- scale(train_pca_matrix, center = mean_train_pca, scale = sd_train_pca)
train_data_standardized <- data.frame(Y = Y_train_standardized, train_pca_standardized)
# Fit the VAR model without additional lagging
var_model <- VAR(train_data_standardized, p = 1)
# Forecast the next step
current_test_pca <- matrix(test_pca_matrix[i, ], nrow = 1)
test_pca_standardized <- scale(current_test_pca, center = mean_train_pca, scale = sd_train_pca)
var_forecast <- predict(var_model, n.ahead = 1)
prediction_standardized <- var_forecast$fcst$Y[1, "fcst"]
# De-standardize the prediction
prediction <- prediction_standardized * sd_Y_train + mean_Y_train
predictions[i] <- prediction
# Update training data
actual_value <- Y_test_vec[i]
Y_train_vec <- c(Y_train_vec, actual_value)
train_pca_matrix <- rbind(train_pca_matrix, test_pca_matrix[i, ])
}
# Metrics
actual_values <- Y_test_vec[1:n_test]
test_errors <- actual_values - predictions
test_mae <- mean(abs(test_errors))
test_mse <- mean(test_errors^2)
test_rmse <- sqrt(test_mse)
# Store metrics
results[results$PCs == pc, ] <- c(pc, test_mae, test_mse, test_rmse)
# Print metrics for the current PC configuration
cat("PCs:", pc, "MAE:", test_mae, "MSE:", test_mse, "RMSE:", test_rmse, "\n")
# Prepare data frame for plotting
df_test <- data.frame(Date = Y_test_with_date$date, Actual = actual_values, Predicted = predictions)
# Save plots in the specified folder
base_filename <- file.path(output_folder, paste0("var_pca_", pc, "_pcs"))
# Time series plot
time_series_plot <- ggplot(df_test, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = Predicted, color = "Predicted")) +
labs(title = paste("VAR with", pc, "PCs: Actual vs Predicted"),
x = "Date", y = "CPIULFSL", color = "Legend") +
theme_minimal() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))
ggsave(paste0(base_filename, "_timeseries.pdf"), plot = time_series_plot, width = 10, height = 8, dpi = 300, units = "in")
# Residual plot
residual_plot <- ggplot(df_test, aes(x = Actual, y = Actual - Predicted)) +
geom_point() +
geom_hline(yintercept = 0, color = "red") +
ggtitle(paste("VAR Residual Plot (PCs =", pc, ")")) +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(paste0(base_filename, "_residuals.pdf"), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle(paste("VAR with", pc, "PCs: Actual vs Predicted")) +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(paste0(base_filename, "_scatter.pdf"), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
}
return(results)
}
# Define the number of PCs to test
pc_values <- c(5, 10, 15, 20, 25, 30, 35, 40)
output_folder <- "var_pca_results"
results <- perform_var_with_pca(pc_values, output_folder)
suppressWarnings(suppressMessages({
library(stats)
library(vars)
library(ggplot2)
}))
perform_var_with_pca <- function(pc_values, output_folder) {
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Initialize variables for recursive rolling predictions
Y_train_vec <- as.numeric(Y_train)
X_train_matrix <- as.matrix(X_train)
Y_test_vec <- as.numeric(Y_test)
X_test_matrix <- as.matrix(X_test)
# Perform PCA once on the training data
train_pca <- prcomp(X_train_matrix, center = TRUE, scale. = TRUE)
test_pca <- predict(train_pca, newdata = X_test_matrix)  # Transform test data
# Data frame to store results
results <- data.frame(PCs = pc_values, MAE = NA, MSE = NA, RMSE = NA)
for (pc in pc_values) {
cat("Testing VAR with", pc, "PCs\n")
# Select the required number of PCs
train_pca_matrix <- train_pca$x[, 1:pc]
test_pca_matrix <- test_pca[, 1:pc]
n_test <- length(Y_test_vec)
predictions <- numeric(n_test)
for (i in 1:n_test) {
# Ensure alignment of `Y_train_vec` and `train_pca_matrix`
rows_to_keep <- min(length(Y_train_vec), nrow(train_pca_matrix))
Y_train_aligned <- Y_train_vec[1:rows_to_keep]
train_pca_aligned <- train_pca_matrix[1:rows_to_keep, ]
# Standardize the current training data
mean_Y_train <- mean(Y_train_aligned)
sd_Y_train <- sd(Y_train_aligned)
Y_train_standardized <- (Y_train_aligned - mean_Y_train) / sd_Y_train
mean_train_pca <- colMeans(train_pca_aligned)
sd_train_pca <- apply(train_pca_aligned, 2, sd)
train_pca_standardized <- scale(train_pca_aligned, center = mean_train_pca, scale = sd_train_pca)
train_data_standardized <- data.frame(Y = Y_train_standardized, train_pca_standardized)
# Fit the VAR model without additional lagging
var_model <- VAR(train_data_standardized, p = 1)
# Forecast the next step
current_test_pca <- matrix(test_pca_matrix[i, ], nrow = 1)
test_pca_standardized <- scale(current_test_pca, center = mean_train_pca, scale = sd_train_pca)
var_forecast <- predict(var_model, n.ahead = 1)
prediction_standardized <- var_forecast$fcst$Y[1, "fcst"]
# De-standardize the prediction
prediction <- prediction_standardized * sd_Y_train + mean_Y_train
predictions[i] <- prediction
# Update training data
actual_value <- Y_test_vec[i]
Y_train_vec <- c(Y_train_vec, actual_value)
train_pca_matrix <- rbind(train_pca_matrix, test_pca_matrix[i, ])
}
# Metrics
actual_values <- Y_test_vec[1:n_test]
test_errors <- actual_values - predictions
test_mae <- mean(abs(test_errors))
test_mse <- mean(test_errors^2)
test_rmse <- sqrt(test_mse)
# Store metrics
results[results$PCs == pc, ] <- c(pc, test_mae, test_mse, test_rmse)
# Print metrics for the current PC configuration
cat("PCs:", pc, "MAE:", test_mae, "MSE:", test_mse, "RMSE:", test_rmse, "\n")
# Prepare data frame for plotting
df_test <- data.frame(Date = Y_test_with_date$date, Actual = actual_values, Predicted = predictions)
# Save plots in the specified folder
base_filename <- file.path(output_folder, paste0("var_pca_", pc, "_pcs"))
# Time series plot
time_series_plot <- ggplot(df_test, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = Predicted, color = "Predicted")) +
labs(title = paste("VAR with", pc, "PCs: Actual vs Predicted"),
x = "Date", y = "CPIULFSL", color = "Legend") +
theme_minimal() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))
ggsave(paste0(base_filename, "_timeseries.pdf"), plot = time_series_plot, width = 10, height = 8, dpi = 300, units = "in")
# Residual plot
residual_plot <- ggplot(df_test, aes(x = Actual, y = Actual - Predicted)) +
geom_point() +
geom_hline(yintercept = 0, color = "red") +
ggtitle(paste("VAR Residual Plot (PCs =", pc, ")")) +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(paste0(base_filename, "_residuals.pdf"), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle(paste("VAR with", pc, "PCs: Actual vs Predicted")) +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(paste0(base_filename, "_scatter.pdf"), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
}
return(results)
}
# Define the number of PCs to test
pc_values <- c(5, 10, 15, 20, 25, 30, 35, 40)
output_folder <- "var_pca_results"
results <- perform_var_with_pca(pc_values, output_folder)
# Load required libraries
suppressWarnings(suppressMessages({
library(randomForest)
library(ggplot2)
}))
perform_rf <- function(ntree, maxnodes = NULL, use_all_predictors = TRUE, title, filename, output_folder) {
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Initialize variables for recursive rolling predictions
Y_train_vec <- as.numeric(Y_train)
X_train_matrix <- as.matrix(X_train)
Y_test_vec <- as.numeric(Y_test)
X_test_matrix <- as.matrix(X_test)
n_test <- length(Y_test_vec)
predictions <- numeric(n_test)
for (i in 1:n_test) {
# Prepare predictors
if (use_all_predictors) {
X_train_rf <- as.data.frame(X_train_matrix)
new_X <- as.data.frame(matrix(X_test_matrix[i, ], nrow = 1))
} else {
X_train_rf <- as.data.frame(X_train_matrix[, "CPIULFSL", drop = FALSE])
new_X <- as.data.frame(matrix(X_test_matrix[i, "CPIULFSL", drop = FALSE], nrow = 1))
}
colnames(new_X) <- colnames(X_train_rf)
# Train RF model
rf_model <- randomForest(X_train_rf, Y_train_vec, ntree = ntree, maxnodes = maxnodes)
# Predict
predictions[i] <- predict(rf_model, newdata = new_X)
# Update training data
Y_train_vec <- c(Y_train_vec, Y_test_vec[i])
X_train_matrix <- rbind(X_train_matrix, X_test_matrix[i, ])
}
# Metrics
test_errors <- Y_test_vec - predictions
test_mae <- mean(abs(test_errors))
test_mse <- mean(test_errors^2)
test_rmse <- sqrt(test_mse)
cat("Number of Trees:", ntree, "\n")
if (!is.null(maxnodes)) {
cat("Max Depth:", maxnodes, "\n")
} else {
cat("Max Depth: Unlimited\n")
}
cat("Test MAE:", test_mae, "\n")
cat("Test MSE:", test_mse, "\n")
cat("Test RMSE:", test_rmse, "\n\n")
# Diagnostic plots
df_test <- data.frame(Date = Y_test_with_date$date[1:n_test],
Actual = Y_test_vec,
Predicted = predictions)
# Time series plot
time_series_plot <- ggplot(df_test, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = Predicted, color = "Predicted")) +
labs(title = title, x = "Date", y = "CPIULFSL", color = "Legend") +
theme_minimal() +
scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red"))
ggsave(file.path(output_folder, filename), plot = time_series_plot, width = 10, height = 8, dpi = 300, units = "in")
# Residual plot
residual_plot <- ggplot(df_test, aes(x = Actual, y = Actual - Predicted)) +
geom_point() +
geom_hline(yintercept = 0, color = "red") +
ggtitle(paste("RF Residual Plot (ntree =", ntree, ")")) +
labs(x = "Actual", y = "Residual (Actual - Predicted)") +
theme_minimal()
ggsave(file.path(output_folder, sub(".pdf", "_residuals.pdf", filename)), plot = residual_plot, width = 10, height = 8, dpi = 300, units = "in")
# Actual vs Predicted scatter plot
scatter_plot <- ggplot(df_test, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
ggtitle(paste("RF Actual vs Predicted (ntree =", ntree, ")")) +
labs(x = "Actual", y = "Predicted") +
theme_minimal()
ggsave(file.path(output_folder, sub(".pdf", "_scatter.pdf", filename)), plot = scatter_plot, width = 10, height = 8, dpi = 300, units = "in")
}
# Reduced configurations for better balance between runtime and exploration
perform_rf(ntree = 50, maxnodes = 10, use_all_predictors = TRUE,
title = "RF with All Predictors (50 Trees, Max Depth 10)",
filename = "rf_all_predictors_50_trees_10_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 100, maxnodes = 15, use_all_predictors = FALSE,
title = "RF with Past Values Only (100 Trees, Max Depth 15)",
filename = "rf_past_value_100_trees_15_depth.pdf",
output_folder = "rf_results")
# Test only inflation
perform_rf(ntree = 10, maxnodes = 5, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (10 Trees, Max Depth 5)",
filename = "rf_past_value_10_trees_5_depth.pdf",
output_folder = "rf_results")
# Test only inflation
perform_rf(ntree = 10, maxnodes = 5, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (10 Trees, Max Depth 5)",
filename = "rf_past_value_10_trees_5_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 50, maxnodes = 10, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (50 Trees, Max Depth 10)",
filename = "rf_past_value_50_trees_10_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 100, maxnodes = 15, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (100 Trees, Max Depth 15)",
filename = "rf_past_value_100_trees_15_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 200, maxnodes = 20, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (200 Trees, Max Depth 20)",
filename = "rf_past_value_200_trees_20_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 500, maxnodes = 25, use_all_predictors = FALSE,
title = "RF with Past CPIULFSL Only (500 Trees, Max Depth 25)",
filename = "rf_past_value_500_trees_25_depth.pdf",
output_folder = "rf_results")
# Test all predictors
perform_rf(ntree = 10, maxnodes = 5, use_all_predictors = TRUE,
title = "RF with All Predictors (10 Trees, Max Depth 5)",
filename = "rf_all_predictors_10_trees_5_depth.pdf",
output_folder = "rf_results")
perform_rf(ntree = 50, maxnodes = 10, use_all_predictors = TRUE,
title = "RF with All Predictors (50 Trees, Max Depth 10)",
filename = "rf_all_predictors_50_trees_10_depth.pdf",
output_folder = "rf_results")
View(Y_before_splitting)
View(X_before_splitting)
View(Y_before_splitting)
# Check if CPIULFSL is a column in X_before_splitting
if ("CPIULFSL" %in% colnames(X_before_splitting)) {
print("CPIULFSL is present in X_before_splitting.")
} else {
print("CPIULFSL is NOT present in X_before_splitting!")
}
